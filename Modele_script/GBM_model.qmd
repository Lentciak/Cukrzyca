---
title: "test_diabetes_xgboost"
author: "Szymon Olędzki, Igor Nowiński"
format: html
theme: 
  dark: darkly
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(caret)
library(doSNOW)
```

```{r}
#Załadowanie zbioru danych
dane <- read.csv("diabetes_binary.csv", header = TRUE, sep = ",", dec = ".")
```

```{r}
#Podział zbioru na zmienne jakościowe i ilościowe, 
#dodatkowo utworzenie podzbioru wyłącznie ze zmiennymi jakościowymi

numeric_vars <- c('BMI', 'MentHlth', 'PhysHlth')

num_vars_cols <- which(colnames(dane) %in% numeric_vars)

dane <- dane %>%
  mutate(across(!all_of(num_vars_cols), as.factor))

#Należy dodatkowo wyróżnić zmienne, w których ważny jest porządek danych wartości nominalnych, jak np. wiek. Z tego powodu musimy je dodatkowo uporządkować.

with_order_vars <- c('Age', 'Education', 'Income', 'GenHlth')

dane <- dane %>%
  mutate(across(all_of(with_order_vars), as.ordered))

dane$GenHlth <- fct_rev(dane$GenHlth)

#Pozbywamy się również duplikatów danych ze zbioru
dane <- distinct(dane)
```

```{r}
#Usuwamy ze zbioru zmienne o niskiej wariancji, bo nie wniosą do modelu istotnych informacji
dane <- dane[,-nearZeroVar(dane)]
```

```{r}
#Łączymy pierwsze 3 poziomy zmiennej 'Education', ze względu na bardzo niewielką ilość informacji jaką przekazują osobno

dane$Education <- fct_collapse(dane$Education, '3-' = c('1', '2', '3'))
```

```{r}
#Dodatkowo zmieniamy poziomy naszej zmiennej objaśniającej na 'yes'(1) i 'no'(0) (konieczne dla poprawnego działania RandomForest i XGBoost)
levels(dane$Diabetes_binary) <- c('no', 'yes')
```

```{r}
#PODZIAŁ DANYCH
set.seed(2024)

trainIndex <- createDataPartition(dane$Diabetes_binary,
                                  p = .75,
                                  list = FALSE)

dane.train <- dane[trainIndex,]
dane.test <- dane[-trainIndex,]
```

```{r}
#TRENING GBM
start <- Sys.time()
ctrl_train <- trainControl(method = "repeatedcv",
                           number = 10, 
                           repeats = 5,
                           returnResamp = 'none',
                           summaryFunction = twoClassSummary,
                           classProbs = T,
                           savePredictions = T,
                           verboseIter = F,
                           allowParallel = T,
                           sampling = 'down')

gbmGrid <-  expand.grid(interaction.depth = 6,
                        n.trees = 500,                                      
                        shrinkage = 0.01,                                   
                        n.minobsinnode = 10)

cl <- makeCluster(6, type = 'SOCK')
registerDoSNOW(cl)

mod_GBM <- train(Diabetes_binary ~ ., 
             data = dane.train,
             method = 'gbm',
             trControl = ctrl_train,
             tuneGrid = gbmGrid,
             metric = 'ROC')

stopCluster(cl)
koniec <- Sys.time()
```

```{r}
#THRESHOLDER DLA GBM
probs <- seq(.01, 0.99, by = 0.01)

ths <- thresholder(mod_xgboost,
                   threshold = probs,
                   final = TRUE,
                   statistics = "all")
```

```{r}
#Utworzenie predykcji na zbiorze testowym na podstawie thresholdera
predykcja <- predict(mod_GBM, dane.test, type = 'prob')

predykcja <- ifelse(predykcja[,1] >= 0.47, 'no', 'yes') #0.47 daje najlepszy balans między Sensitivity i Specificity (ok. 73% oba)

conf_mat <- cvms::confusion_matrix(targets = dane.test$Diabetes_binary,
                                    predictions = as.factor(predykcja),
                                    positive = 'yes')

cvms::plot_confusion_matrix(conf_mat,
                            counts_on_top = T,
                            add_normalized = F,
                            rotate_y_text = F,
                            add_row_percentages = F,
                            font_counts = list(size = 9),
                            font_col_percentages = list(size = 7))
```

```{r}
#Zapis modelu do pliku
saveRDS(mod_GBM, "Modele/gbm_model.rds")
```
